{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progetto Emotion Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzione \"indici\"\n",
    "Questa funzione è stata creata per migliorare, a livello di efficienza, il calcolo delle distanze tra tutti i landmark presenti all'interno di ogni frame. In particolare, attraverso la funzione **indici**, sono stati creati tutte le combinazioni di punti dei landmark e messi all'interno di un array. \n",
    "Gli elementi dell'array saranno utili per il calcolo delle distanze dei punti dei landmark, evitando di calcolare distanze superflue. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo di tutte le combinazioni tra i landmark\n",
    "def indici():\n",
    "    print(\"Calcolo gli indici...\")\n",
    "    arrayIndici = []\n",
    "    for i in range(1, 69):\n",
    "        for j in range(i + 1, 69):\n",
    "            arrayIndici.append((i, j))\n",
    "    return arrayIndici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzione \"distanza_punti\"\n",
    "Questa funzione va ad effettuare il calcolo della distanza tra 2 punti. In particolare, ricevento le coordinate dei punti, viene applicata la formula e ritornato il risultato.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo della distanza tra 2 punti\n",
    "def distanza_punti(x1, x2, y1, y2):\n",
    "    print(\"x1:\" + str(x1) + \" x2: \" + str(x2) + \" y1:\" + str(y1) + \" y2: \" + str(y2))\n",
    "    return math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzione \"crea_Distanze\"\n",
    "Questa funzione crea una matrice (dataset) contenente tutte le distanze tra tutti i punti dei landmarks di ogni frame. In particolare, su ogni riga, saranno memorizzate tutte le distanze appartenenti ad un determinato frame. \n",
    "Tutto questo calcolo, viene fatto prendendo i dati (relativi ad ogni punto) dal dataset che riceve in input e analizzando l'array \"indici\" (sempre ricevuto in input) prende le coppie da analizzare e effettua il calcolo delle distenze attraverso le funzione \"distanza_punti\", memorizzando ogni distanza in questa matrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del dataset contenente le distanze tra tutte le coppie di landmark ricavati da ogni immagine\n",
    "def crea_Distanze(indici, dataset):\n",
    "    print(\"Procedo al calcolo delle distanze tra i landmark...\")\n",
    "    distanze = np.empty((0, 2280))\n",
    "    counter = 0\n",
    "    for list in dataset:\n",
    "        array = []\n",
    "        array = np.append(array, list[0])\n",
    "        array = np.append(array, list[1])\n",
    "        for indice in indici:\n",
    "            print(\"(\" + str(indice[0]) + \",\" + str(indice[1]) + \")\")\n",
    "            punto1_x = indice[0]*2\n",
    "            punto2_x = indice[1]*2\n",
    "            punto1_y = indice[0]*2+1\n",
    "            punto2_y = indice[1]*2+1\n",
    "            print(\"x1:\" + str(punto1_x) + \" y1: \" + str(punto1_y) + \" x2:\" + str(punto2_x) + \" y2: \" + str(punto2_y))\n",
    "            array = np.append(array, distanza_punti(float(dataset[counter, punto1_x]),\n",
    "                                                    float(dataset[counter, punto2_x]), float(dataset[counter, punto1_y]),\n",
    "                                                    float(dataset[counter, punto2_y])))\n",
    "        counter += 1\n",
    "        distanze = np.vstack([distanze, array])\n",
    "\n",
    "    return distanze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzione \"create_column\"\n",
    "Questa funzione è stata creata semplicemente per creare le label per le colonne del dataset. In input riceve il parametro \"type\" e ciò è stato fatto per poter creare 2 tipi diversi di labels. In particolar modo con \"type\" = 1 crea le label che si riferiscono ai landmark trovati, con \"type\" = 0 invece, crea le label che si riferiscono al dataset delle distanze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione delle labels per le colonne del dataset\n",
    "def create_column(type):\n",
    "    labels = []\n",
    "    labels.append(\"Subject_ID\")\n",
    "    labels.append(\"Emotion_ID\")\n",
    "    if(type):\n",
    "        for i in range(0, 68):\n",
    "            label1 = \"landmark_\" + str(i) + \"_x\"\n",
    "            label2 = \"landmark_\" + str(i) + \"_y\"\n",
    "            labels.append(label1)\n",
    "            labels.append(label2)\n",
    "\n",
    "    else:\n",
    "        arrayIndici = indici()\n",
    "        print(len(arrayIndici))\n",
    "        for i in range(0, 2278):\n",
    "            label1 = \"distance\" + str(arrayIndici[i])\n",
    "            labels.append(label1)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzione \"max_timestep\"\n",
    "Questa funzione viene utilizzata per trovare il timestep massimo all'interno del dataset che contiene le distanze tra tutti i landmark individuati nei frame. In particolar modo, la funzione, ricevendo in input il dataframe, lo scandisce riga per riga e conta, per ogni video, quanti frame contiene. Il numero massimo di frame individuato, verrà dato in output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ricerca Del massimo numero di Frame/Timestamp\n",
    "def max_timestep(df):\n",
    "    max = 0\n",
    "    count = 0\n",
    "    before = np.empty(0)\n",
    "    before = np.append(before, df[0,0])\n",
    "    before = np.append(before, df[0,1])\n",
    "\n",
    "    for row in df:\n",
    "        if(row[0] == before[0] and int(row[1])==int(before[1])):\n",
    "            count = count + 1\n",
    "        else:\n",
    "            if(count > max):\n",
    "                max = count\n",
    "            count = 1\n",
    "\n",
    "        before[0] = row[0]\n",
    "        before[1] = row[1]\n",
    "\n",
    "    return max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzione \"fillingData\" e \"zeroFillingData\"\n",
    "La funzioni \"fillingData\" e \"zeroFillingData\" si occupano di riempire i dati presenti nel dataset distanze. In particolare dato che la rete neurale riccorente (nel caso in questione l'LSTM) vuole in input video con lo stesso numero di frame, questa funzione andrà a riempire il dataset in modo tale da avere per ogni video lo stesso numero di frame. La funzione \"fillingData\" quindi, ricevendo in input il dataframe e il timestep aggiungerà per ogni video, delle righe (prima e dopo i frames) contenenti tutti 0, in modo tale da avere video con numero di frame tutti uguali. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillingData(df,timestep):\n",
    "\n",
    "    count = 0\n",
    "    before = np.empty(0)\n",
    "    before = np.append(before, df[0,0])\n",
    "    before = np.append(before, df[0,1])\n",
    "    appoggio = []\n",
    "    dataframe = np.empty((0, 2280))\n",
    "\n",
    "\n",
    "    for row in df:\n",
    "        if(row[0] == before[0] and int(row[1])==int(before[1])):\n",
    "            count = count + 1\n",
    "            appoggio.append(row)\n",
    "        else:\n",
    "            dataframe = zeroFillingData(count,timestep, before, appoggio, dataframe)\n",
    "\n",
    "            appoggio = []\n",
    "            count = 1\n",
    "\n",
    "        before[0] = row[0]\n",
    "        before[1] = row[1]\n",
    "\n",
    "    dataframe = zeroFillingData(count, timestep, before, appoggio, dataframe)\n",
    "\n",
    "    filling = pd.DataFrame(data=dataframe, columns=create_column(0))\n",
    "    return filling\n",
    "\n",
    "def zeroFillingData(count, timestep, before, appoggio, dataframe):\n",
    "    if (count < timestep):\n",
    "        diff = timestep - count\n",
    "        div = diff // 2\n",
    "        labels = []\n",
    "        labels.append(before[0])\n",
    "        labels.append(before[1])\n",
    "        for x in range(2, 2280):\n",
    "            labels.append(0)\n",
    "        for x in range(0, div):\n",
    "            dataframe = np.vstack([dataframe, labels])\n",
    "\n",
    "        dataframe = np.vstack([dataframe, appoggio])\n",
    "\n",
    "        for x in range(0, diff - div):\n",
    "            dataframe = np.vstack([dataframe, labels])\n",
    "    else:\n",
    "        if (count == timestep):\n",
    "            dataframe = np.vstack([dataframe, appoggio])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scansione Cartelle\n",
    "\n",
    "In questo snippet di codice, vengono scansionate in maniera automatica tutte le cartelle presenti nel dataset, andando a prendere frame per frame ed analizzandono, estraendo attraverso il detector di punti facciali tutti i 68 landmark. Una volta estratti tutti, per ogni punto verranno calcolati x e y e memorizzati sequenzialemente all'interno della matrice. La matrice quindi conterrà, per ogni riga, tutti i 68 landmark relativi ad un determinato frame. Da questa matrice, successivamente, si è creato il dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcolo i landmark per l'emozione 001 del soggetto S010 Frame: 1...\n",
      "Calcolo i landmark per l'emozione 001 del soggetto S010 Frame: 2...\n",
      "Calcolo i landmark per l'emozione 001 del soggetto S010 Frame: 3...\n",
      "Calcolo i landmark per l'emozione 001 del soggetto S010 Frame: 4...\n",
      "Calcolo i landmark per l'emozione 001 del soggetto S010 Frame: 5...\n",
      "Calcolo i landmark per l'emozione 001 del soggetto S010 Frame: 6...\n",
      "Calcolo i landmark per l'emozione 001 del soggetto S010 Frame: 7...\n",
      "Calcolo i landmark per l'emozione 001 del soggetto S010 Frame: 8...\n",
      "Calcolo i landmark per l'emozione 001 del soggetto S010 Frame: 9...\n",
      "Calcolo i landmark per l'emozione 001 del soggetto S010 Frame: 10...\n",
      "Calcolo i landmark per l'emozione 001 del soggetto S010 Frame: 11...\n",
      "Calcolo i landmark per l'emozione 001 del soggetto S010 Frame: 12...\n",
      "Calcolo i landmark per l'emozione 001 del soggetto S010 Frame: 13...\n",
      "Calcolo i landmark per l'emozione 001 del soggetto S010 Frame: 14...\n"
     ]
    }
   ],
   "source": [
    "labels = p_u.create_column(0)\n",
    "print(len(labels))\n",
    "labels = p_u.create_column(1)\n",
    "dataset = np.empty((0, 138))\n",
    "\n",
    "# Scansione cartelle\n",
    "for cartella, sottocartelle, files in os.walk(\"/Users/michelantoniopanichella/PycharmProjects/FVAB-Emotion_Recognition/CK+/cohn-kanade-images/S010/001\"):\n",
    "    count = 0\n",
    "    for image in files:\n",
    "        if image.endswith(\".png\"):\n",
    "\n",
    "            subjectID = image[0:4]\n",
    "            emotionID = image[5:8]\n",
    "            count += 1\n",
    "            print(\"Calcolo i landmark per l'emozione \" + emotionID + \" del soggetto \" + subjectID + \" Frame: \"+ str(count) +\"...\")\n",
    "\n",
    "            img = cv2.imread(cartella + '/' + image)\n",
    "\n",
    "            # Landmark points detector\n",
    "            p = '/Users/michelantoniopanichella/PycharmProjects/FVAB-Emotion_Recognition/Exercise/shape_predictor_68_face_landmarks.dat'\n",
    "            detector = dlib.get_frontal_face_detector()\n",
    "            predictor = dlib.shape_predictor(p)\n",
    "\n",
    "            faces = detector(img)\n",
    "\n",
    "            for face in faces:\n",
    "                landmarks = predictor(img, face)\n",
    "                landmarks_points = []\n",
    "                landmarks_points.append(subjectID)\n",
    "                landmarks_points.append(emotionID)\n",
    "                for n in range(0, 68):\n",
    "                    x = landmarks.part(n).x\n",
    "                    y = landmarks.part(n).y\n",
    "                    landmarks_points.append(x)\n",
    "                    landmarks_points.append(y)\n",
    "\n",
    "                dataset = np.vstack([dataset, landmarks_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['S010' '001' '262' ... '351' '369' '350']\n",
      " ['S010' '001' '259' ... '360' '365' '358']\n",
      " ['S010' '001' '260' ... '360' '365' '358']\n",
      " ...\n",
      " ['S010' '001' '264' ... '348' '368' '347']\n",
      " ['S010' '001' '261' ... '359' '367' '358']\n",
      " ['S010' '001' '262' ... '359' '367' '358']]\n"
     ]
    }
   ],
   "source": [
    "##Creazione del file csv contente i landmark\n",
    "df = pd.DataFrame(data=dataset, columns=labels)\n",
    "df.to_csv('/Users/michelantoniopanichella/PycharmProjects/FVAB-Emotion_Recognition/Exercise/dataset.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/michelantoniopanichella\n"
     ]
    }
   ],
   "source": [
    "# Creazione del dataset contenente le distanze a partire dal DataFrame contenente le posizioni dei landmark\n",
    "arrayIndici = indici()\n",
    "distanze = pd.DataFrame(data=crea_Distanze(arrayIndici, dataset))\n",
    "distanze.to_csv('../Exercise/distanze.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import PreprocessingUtilities as p_u\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Masking\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizzazione\n",
    "\n",
    "In questo snippet di codice sottostante quello che si è andato a fare è prendere il file contenente i dati processati (ossia i dati dei video con l'aggiunta dei frame composti da soli 0) e normalizzarli portandoli dunque tutti ad una grandezza compresa tra 0 e 1). Per fare ciò però è stata fatta prima una reshape in modo tale da avere tutti i dati in una sola colonna e applicare quindi lo \"scaler\" attraverso le funzioni fit e trasform. Una volta fatto ciò i dati sono stati \"riorganizzati\" di nuovo con una reshape ed è stato creato un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('filling_nuovissimo.csv')\n",
    "columns = ds.columns[2:]\n",
    "y = ds['Emotion_ID']\n",
    "ds = ds.drop(['Emotion_ID', 'Subject_ID'], axis=1)\n",
    "X = ds.to_numpy()\n",
    "X = np.reshape(X, (X.shape[0]*X.shape[1], 1))\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "print(X.shape[0]/2278)\n",
    "X = np.reshape(X, (X.shape[0]//2278, 2278))\n",
    "ds = pd.DataFrame(X, columns=columns)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Selection\n",
    "\n",
    "Nel seguento passo è stata fatta una feature selection. In particolar modo sono state eliminate tutte le feature meno essenziali che, nel nostro caso, sono quelle riferite alla parte esterna del volto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indici = p_u.indici()\n",
    "c = []\n",
    "for element in indici:\n",
    "    if(element[0]>=32 and element[1]>=32):  \n",
    "        c.append('distance'+str(element))\n",
    "ds = ds[c]\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrazione dati test e training\n",
    "\n",
    "Nel codice qui presentato, è stato diviso l'intero dataframe in 2 sottoinsiemi: training set e test set. Dato che in questo caso abbiamo video contenti diversi frame, per poter usufruire della funzione \"train_test_split\", abbiamo ristrutturato il dataframe in una array a 3 dimensioni, in cui ad ogni riga corrisponde un video che contiene i diversi frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ds.to_numpy().shape[1]\n",
    "labels = []\n",
    "timestep = 71\n",
    "for i in range(0, y.shape[0]//timestep):\n",
    "    labels.append(y[i*timestep])\n",
    "y = np.asarray(labels, dtype='int64')\n",
    "# 3D reshape\n",
    "X = np.reshape(ds.to_numpy(), (ds.to_numpy().shape[0] // timestep, timestep, features))\n",
    "X = np.asarray(X, dtype='float64')\n",
    "#train test split\n",
    "print(X.shape)\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "test_x, val_data_x, test_y, val_data_y = train_test_split(test_x, test_y, test_size=0.5, random_state=42)\n",
    "print(train_y)\n",
    "print(test_y)\n",
    "print(val_data_y)\n",
    "#test_y = to_categorical(test_y-1)\n",
    "train_y = to_categorical(train_y-1)\n",
    "val_data_y = to_categorical(val_data_y-1)\n",
    "y = to_categorical(y-1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costruzione rete neurale LSTM\n",
    "\n",
    "Nella funzione \"modelCostruction\" si è costruito il modello che andrà ad esaminare i nostri dati e fare eventualemtne delle previsioni su altri in input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose, epochs, batch_size = 1, 250, 6\n",
    "def modelConstruction():\n",
    "  # model construction\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=(timestep, features)))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "  # output layer\n",
    "    model.add(Dense(train_y.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta addestrata la rete neurale è stata testata la validità del modello costruito attraverso la Cross Validation con 5 cicli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KerasClassifier(build_fn = modelConstruction, batch_size=batch_size, epochs=200) \n",
    "accuracies = cross_val_score(estimator=clf, X=X, y=y, cv=5, error_score='raise') # cv = 5\n",
    "print(accuracies)\n",
    "print(\"Mean accuracy: \" + str(accuracies.mean()))\n",
    "print(\"Variance: \"+str(accuracies.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelConstruction()\n",
    "history = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data=(val_data_x, val_data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(model.predict(test_x), axis=-1)+1\n",
    "tot = test_y.shape\n",
    "count = np.sum(pred==test_y)\n",
    "print(\"Accuracy: \"+str(count/tot))\n",
    "mat = confusion_matrix(test_y, pred)\n",
    "cfmt_df = pd.DataFrame(mat, range(mat.shape[0]), range(mat.shape[1]))\n",
    "sn.heatmap(cfmt_df, annot=True, annot_kws={\"size\": 16}) \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
